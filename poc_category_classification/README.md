# PoC: ClasificaciÃ³n de CategorÃ­as con Embeddings

> **VersiÃ³n:** 1.0 | **Estado:** âœ… Completo | **Fecha:** 2025-11-20

## ğŸ¯ Objetivo

Proof of Concept (PoC) para evaluar el uso de **embeddings semÃ¡nticos** en la clasificaciÃ³n de titulares por categorÃ­as temÃ¡ticas, comparando su rendimiento con el mÃ©todo actual basado en **LLM (gpt-4o-mini)**.

**Preguntas clave a responder:**
- Â¿QuÃ© tan precisa es la clasificaciÃ³n con embeddings vs LLM?
- Â¿CuÃ¡nto mÃ¡s rÃ¡pida y econÃ³mica es la alternativa con embeddings?
- Â¿En quÃ© categorÃ­as funciona mejor/peor?
- Â¿Es viable integrar embeddings en el pipeline de producciÃ³n?

## ğŸ—ï¸ Arquitectura

```
poc_category_classification/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ requirements.txt                   # Dependencias Python
â”œâ”€â”€ config.yml                         # ConfiguraciÃ³n principal
â”œâ”€â”€ run_classification.py              # Script principal (ejecutable)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db_loader.py                   # Carga URLs clasificadas desde news.db
â”‚   â”œâ”€â”€ category_classifier.py         # Clasificador basado en embeddings
â”‚   â””â”€â”€ comparison_analyzer.py         # AnÃ¡lisis y mÃ©tricas de comparaciÃ³n
â””â”€â”€ output/                            # Informes generados (Markdown + CSV)
```

**Dependencias externas:**
- `poc_clustering/src/embedder.py` - Reutiliza generador de embeddings

## ğŸš€ Quick Start

### 1. Setup

```bash
# Navegar al directorio del PoC
cd poc_category_classification

# Crear entorno virtual (opcional)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt

# NOTA: El modelo de embeddings se descargarÃ¡ automÃ¡ticamente
# en la primera ejecuciÃ³n (~100MB) y se cachea en:
# ../poc_clustering/models_cache/
```

### 2. ConfiguraciÃ³n

Editar `config.yml` para ajustar parÃ¡metros:

```yaml
database:
  filters:
    max_urls: 200  # Limitar para test rÃ¡pido (null = todas)

classification:
  method: cosine_similarity
  similarity_threshold: 0.5
  use_examples: true
  examples_per_category: 3

output:
  export_csv: true
  include_performance_comparison: true
```

### 3. EjecuciÃ³n

```bash
# Ejecutar con configuraciÃ³n por defecto
./run_classification.py

# Especificar config custom
./run_classification.py --config mi_config.yml

# Especificar output path
./run_classification.py --output mi_informe.md
```

### 4. Resultados

El script genera dos archivos en `output/`:
- `classification_report_YYYYMMDD_HHMMSS.md` - Informe completo en Markdown
- `classification_report_YYYYMMDD_HHMMSS.csv` - Datos crudos en CSV

## ğŸ“Š Funcionamiento

### Flujo del PoC

```
1. CARGAR DATOS
   â”œâ”€ Leer URLs clasificadas desde news.db (ground truth LLM)
   â””â”€ Aplicar filtros (fecha, categorÃ­as, lÃ­mite)

2. INICIALIZAR MODELO
   â”œâ”€ Cargar modelo de embeddings (intfloat/multilingual-e5-small)
   â””â”€ Generar embeddings de categorÃ­as (descripciÃ³n + ejemplos)

3. CLASIFICAR
   â”œâ”€ Generar embeddings de titulares (batch)
   â””â”€ Calcular similitud coseno con cada categorÃ­a

4. COMPARAR
   â”œâ”€ Contrastar predicciones con ground truth LLM
   â””â”€ Calcular mÃ©tricas (accuracy, precision, recall, F1)

5. ANALIZAR
   â”œâ”€ Matriz de confusiÃ³n
   â”œâ”€ Patrones de errores
   â””â”€ EstadÃ­sticas de confianza

6. REPORTAR
   â””â”€ Generar informe Markdown + exportar CSV
```

### MÃ©todo de ClasificaciÃ³n

**Embeddings de categorÃ­as:**
- Se generan embeddings para la **descripciÃ³n** de cada categorÃ­a
- Opcionalmente se incluyen **ejemplos** (3 por defecto)
- Se combinan usando una estrategia (`mean`, `max`, `weighted_mean`)

**ClasificaciÃ³n de titulares:**
1. Generar embedding del titular
2. Calcular **similitud coseno** con cada categorÃ­a
3. Asignar categorÃ­a con mayor similitud
4. Si similitud < threshold â†’ `otros`

**Ejemplo:**
```
Titular: "Banco Central sube tipos de interÃ©s al 4.5%"

Similitudes:
  economia:    0.892 â† GANADOR
  finanzas:    0.764
  politica:    0.612
  tecnologia:  0.301
  ...

PredicciÃ³n: economia (confianza: 0.892)
Ground truth: economia
Resultado: âœ“ CORRECTO
```

## ğŸ“ˆ MÃ©tricas Reportadas

### MÃ©tricas Globales
- **Accuracy:** % de clasificaciones correctas
- **Precision (macro):** Promedio de precisiÃ³n por categorÃ­a
- **Recall (macro):** Promedio de recall por categorÃ­a
- **F1-Score (macro):** Media armÃ³nica de precision/recall

### MÃ©tricas por CategorÃ­a
- Precision, Recall, F1, Support para cada categorÃ­a individual

### Matriz de ConfusiÃ³n
- Tabla cruzada: verdadero vs predicho
- Identifica pares de categorÃ­as que se confunden frecuentemente

### AnÃ¡lisis de Errores
- Ejemplos concretos de clasificaciones incorrectas
- Patrones de confusiÃ³n mÃ¡s frecuentes (ej: "economia â†’ finanzas")
- EstadÃ­sticas de confianza (similarity scores) para correctos vs incorrectos

### ComparaciÃ³n de Rendimiento
- **Tiempo:** Embeddings vs LLM
- **Costo:** $0 (local) vs ~$0.02-0.04 (API)
- **Memoria:** Uso pico de RAM
- **Latencia:** ClasificaciÃ³n batch

## âš™ï¸ ConfiguraciÃ³n Detallada

### Database Filters

```yaml
database:
  path: ../data/news.db

  filters:
    # Solo URLs con categorÃ­a asignada (LLM ground truth)
    require_categoria: true

    # Rango de fechas (opcional)
    date_from: "2025-11-01"
    date_to: "2025-11-20"

    # LÃ­mite de URLs (null = todas)
    max_urls: 500

    # Filtrar categorÃ­as especÃ­ficas (null = todas)
    categories_filter: ['economia', 'politica', 'tecnologia']
```

### Model Configuration

```yaml
model:
  # Modelo de HuggingFace
  name: intfloat/multilingual-e5-small

  # Cache compartido con poc_clustering
  cache_dir: ../poc_clustering/models_cache

  # Batch size (ajustar segÃºn RAM)
  batch_size: 100

  # Device: 'cpu' o 'cuda'
  device: cpu
```

**Modelos alternativos:**
- `intfloat/multilingual-e5-base` (768 dims, mÃ¡s preciso, mÃ¡s lento)
- `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- `hiiamsid/sentence_similarity_spanish_es`

### Classification Strategy

```yaml
classification:
  # MÃ©todo: 'cosine_similarity', 'knn', 'threshold'
  method: cosine_similarity

  # K para KNN (si method = 'knn')
  knn_k: 5

  # Threshold mÃ­nimo de similitud
  similarity_threshold: 0.5

  # Usar ejemplos ademÃ¡s de descripciÃ³n
  use_examples: true

  # NÃºmero de ejemplos por categorÃ­a
  examples_per_category: 3

  # Estrategia de combinaciÃ³n de embeddings
  # Options: 'mean', 'max', 'weighted_mean'
  category_embedding_strategy: mean
```

**Recomendaciones:**
- `use_examples: true` + `strategy: mean` â†’ Balance precisiÃ³n/generalizaciÃ³n
- `use_examples: false` â†’ MÃ¡s rÃ¡pido, puede perder matices
- `strategy: weighted_mean` â†’ Da mÃ¡s peso a la descripciÃ³n vs ejemplos
- `threshold > 0.6` â†’ MÃ¡s estricto, mÃ¡s casos clasificados como "otros"

### Categories Configuration

```yaml
categories:
  # Path al archivo de categorÃ­as
  config_path: ../config/categories.yml

  # CategorÃ­as a excluir del anÃ¡lisis
  exclude: ['otros']
```

### Output Options

```yaml
output:
  format: markdown

  # MÃ©tricas detalladas por categorÃ­a
  include_per_category_metrics: true

  # Tabla de comparaciÃ³n LLM vs Embeddings
  include_comparison_table: true

  # AnÃ¡lisis de costos y latencia
  include_performance_comparison: true

  # Exportar CSV ademÃ¡s de Markdown
  export_csv: true

  # Directorio de salida
  output_dir: ./output
```

## ğŸ§ª Testing y ValidaciÃ³n

### Test BÃ¡sico

```bash
# Test rÃ¡pido con subset pequeÃ±o
# Editar config.yml:
#   database.filters.max_urls: 50

./run_classification.py

# Revisar output/classification_report_*.md
```

### Test de MÃ³dulos Individuales

```bash
# Test DBLoader
cd src/
python db_loader.py

# Test CategoryClassifier
python category_classifier.py

# Test ComparisonAnalyzer
python comparison_analyzer.py
```

### ValidaciÃ³n de Resultados

**Checklist:**
- [ ] Accuracy > 70% (mÃ­nimo aceptable)
- [ ] Precision/Recall balanceado (no sesgado a categorÃ­as mayoritarias)
- [ ] ConfusiÃ³n entre categorÃ­as similares es esperada (ej: economia â†” finanzas)
- [ ] Confidencias altas para correctos, bajas para incorrectos
- [ ] Tiempo de ejecuciÃ³n < 30s para 200 URLs

## ğŸ“Š Ejemplo de Output

### Console Output

```
============================================================
PoC Category Classification - Embeddings vs LLM
============================================================

ğŸ“„ Loading config: config.yml

ğŸ“¦ Step 1: Loading classified URLs from database...
  Total URLs in DB: 1247
  Classified URLs: 856
  Classification rate: 68.6%
  Loaded 200 URLs for analysis

  Category distribution:
    economia: 58
    politica: 42
    tecnologia: 31
    finanzas: 27
    geopolitica: 24
    sociedad: 12
    deportes: 6

ğŸ¤– Step 2: Loading embedding model...
Loading embedding model: intfloat/multilingual-e5-small
Model loaded. Embedding dimension: 384
  Model loaded in 2.3s

ğŸ¯ Step 3: Initializing category classifier...
Generating category embeddings...
  politica: 4 texts â†’ embedding
  economia: 4 texts â†’ embedding
  finanzas: 4 texts â†’ embedding
  tecnologia: 4 texts â†’ embedding
  geopolitica: 4 texts â†’ embedding
  sociedad: 4 texts â†’ embedding
  deportes: 4 texts â†’ embedding
CategoryClassifier initialized with 7 categories
Method: cosine_similarity, Strategy: mean

ğŸ” Step 4: Classifying 200 URLs with embeddings...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:01<00:00, 145.23it/s]
  Classification completed in 1.4s

ğŸ“Š Step 5: Analyzing results...
Total samples: 200
Correct: 167 (83.5%)
Incorrect: 33 (16.5%)

Overall Metrics:
  Accuracy: 0.835
  Precision (macro): 0.812
  Recall (macro): 0.798
  F1 (macro): 0.804

ğŸ“ Step 6: Generating report...

âœ… Informe generado: output/classification_report_20251120_143052.md
âœ… CSV exported: output/classification_report_20251120_143052.csv

============================================================
âœ… COMPLETED
Total execution time: 5.8s
Peak memory usage: 287.4 MB
============================================================
```

### Markdown Report (excerpt)

```markdown
# ğŸ“Š Informe de ClasificaciÃ³n por CategorÃ­as

**MÃ©todo:** Embeddings vs LLM (ground truth)
**Modelo:** intfloat/multilingual-e5-small
**Generado:** 2025-11-20 14:30:52

---

## ğŸ“ˆ Resumen Ejecutivo

- **Total de URLs analizadas:** 200
- **Accuracy:** 83.50%
- **Precision (macro):** 0.812
- **Recall (macro):** 0.798
- **F1-Score (macro):** 0.804

- **Correctos:** 167 (83.5%)
- **Incorrectos:** 33 (16.5%)

---

## ğŸ“Š MÃ©tricas por CategorÃ­a

| CategorÃ­a | Precision | Recall | F1-Score | Support |
|-----------|-----------|--------|----------|---------|
| deportes     | 1.000 | 1.000 | 1.000 |    6 |
| economia     | 0.864 | 0.862 | 0.863 |   58 |
| finanzas     | 0.704 | 0.704 | 0.704 |   27 |
| geopolitica  | 0.875 | 0.875 | 0.875 |   24 |
| politica     | 0.750 | 0.810 | 0.779 |   42 |
| sociedad     | 0.833 | 0.833 | 0.833 |   12 |
| tecnologia   | 0.857 | 0.774 | 0.814 |   31 |

---

## âš ï¸ Patrones de ConfusiÃ³n MÃ¡s Frecuentes

- **politica â†’ economia:** 5 casos
- **economia â†’ finanzas:** 4 casos
- **finanzas â†’ economia:** 3 casos
- **tecnologia â†’ sociedad:** 2 casos
```

## ğŸ’¡ Hallazgos Esperados

### Ventajas de Embeddings
âœ… **Velocidad:** 5-10x mÃ¡s rÃ¡pido que LLM (batch processing)
âœ… **Costo:** $0 vs ~$0.02-0.04 por ejecuciÃ³n
âœ… **DeterminÃ­stico:** Mismo input â†’ mismo output (reproducible)
âœ… **Escalable:** Sin lÃ­mites de API rate, sin tokens
âœ… **Local:** No dependencia de servicios externos

### Desventajas de Embeddings
âŒ **PrecisiÃ³n menor:** ~75-85% accuracy vs ~90-95% LLM
âŒ **ConfusiÃ³n entre categorÃ­as similares:** economia â†” finanzas, politica â†” economia
âŒ **Menos interpretable:** No "razonamiento" explÃ­cito
âŒ **Requiere calibraciÃ³n:** Threshold y estrategia de embeddings
âŒ **No maneja excepciones complejas:** LLM mejor para casos edge

### CategorÃ­as CrÃ­ticas
- **FÃ¡ciles:** deportes, tecnologia (vocabulario distintivo)
- **DifÃ­ciles:** economia/finanzas, politica/economia (solapamiento semÃ¡ntico)
- **ProblemÃ¡ticas:** sociedad (muy amplia), otros (indefinida)

## ğŸ”„ PrÃ³ximos Pasos

### Mejoras Potenciales
- [ ] **Hybrid approach:** Embeddings para categorÃ­as fÃ¡ciles, LLM para difÃ­ciles
- [ ] **Fine-tuning:** Entrenar clasificador supervisado con datos histÃ³ricos
- [ ] **Ensemble:** Combinar embeddings + LLM con voting
- [ ] **Threshold dinÃ¡mico:** Ajustar por categorÃ­a segÃºn distribuciÃ³n
- [ ] **Aumentar ejemplos:** MÃ¡s ejemplos por categorÃ­a mejora separabilidad

### IntegraciÃ³n en Pipeline
- [ ] **Stage 02 alternativo:** OpciÃ³n `--use-embeddings` en `02_filter_for_newsletters.py`
- [ ] **Modo hÃ­brido:** Embeddings primary, LLM fallback para confidencia baja
- [ ] **A/B testing:** Ejecutar ambos mÃ©todos en paralelo y comparar
- [ ] **Monitoring:** Dashboard para comparar mÃ©tricas en producciÃ³n

### Experimentos Adicionales
- [ ] **Modelos alternativos:** Probar `multilingual-e5-base` (768 dims)
- [ ] **Dimensionality reduction:** PCA/t-SNE para visualizar clusters
- [ ] **Category tuning:** Optimizar descripciones y ejemplos por categorÃ­a
- [ ] **Temporal analysis:** Â¿Cambia accuracy con el tiempo?

## ğŸ› ï¸ Troubleshooting

### Error: "Model not found"
```bash
# Descargar modelo manualmente
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('intfloat/multilingual-e5-small', cache_folder='../poc_clustering/models_cache')"
```

### Error: "Database not found"
```bash
# Verificar path en config.yml
ls -la ../data/news.db

# O ajustar path absoluto
database:
  path: /home/user/newsletter_utils/data/news.db
```

### Memoria insuficiente (Raspberry Pi)
```yaml
# Reducir batch_size en config.yml
model:
  batch_size: 32  # En vez de 100

# O limitar dataset
database:
  filters:
    max_urls: 100
```

### Baja accuracy (<70%)
```yaml
# Ajustar configuraciÃ³n
classification:
  use_examples: true
  examples_per_category: 5  # Aumentar ejemplos
  category_embedding_strategy: weighted_mean

# O probar modelo mÃ¡s grande
model:
  name: intfloat/multilingual-e5-base
```

## ğŸ“š Referencias

- **Modelo de embeddings:** [intfloat/multilingual-e5-small](https://huggingface.co/intfloat/multilingual-e5-small)
- **sentence-transformers:** [Documentation](https://www.sbert.net/)
- **Semantic similarity:** [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)
- **Pipeline principal:** `../CLAUDE.md`
- **PoC Clustering:** `../poc_clustering/README.md`

## ğŸ“ Changelog

- **2025-11-20:** v1.0 - Initial release

---

**Autor:** Generado automÃ¡ticamente por Claude Code
**Licencia:** Mismo que proyecto principal
**Contacto:** Ver README principal del proyecto
