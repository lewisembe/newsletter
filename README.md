# Newsletter Utils - Pipeline de Noticias Automatizado

> Nota: este README refleja el estado inicial (solo Stage 01 completada). El pipeline actual usa PostgreSQL y tiene etapas 2-5 y webapp activas; consulta `DB_SCHEMA_OVERVIEW.md`, los README de `stages/` y `webapp/README.md` para informaciÃ³n reciente.

Pipeline modular en Python para automatizar la obtenciÃ³n, clasificaciÃ³n, anÃ¡lisis y redacciÃ³n de noticias de prensa diaria.

## Estado del Proyecto

### âœ… Etapa 1 - Extract URLs (COMPLETADA)

La primera etapa del pipeline estÃ¡ completamente funcional:

- âœ… Scraping web con Selenium en modo headless
- âœ… ExtracciÃ³n de enlaces desde mÃºltiples fuentes configurables
- âœ… Filtrado inteligente con LLM (OpenAI) para identificar noticias reales vs navegaciÃ³n/ads
- âœ… Guardado en CSV con separador TAB
- âœ… Logging completo por fecha
- âœ… Tests unitarios

### ğŸ”„ PrÃ³ximas Etapas

- â³ Etapa 2: Upsert URLs y clasificaciÃ³n en base de datos
- â³ Etapa 3: Filtrado para newsletters
- â³ Etapa 4: Ranking de titulares
- â³ Etapa 5: ExtracciÃ³n de contenido completo
- â³ Etapa 6: GeneraciÃ³n de newsletters

## InstalaciÃ³n

### Prerrequisitos

- Python 3.11+
- Chromium/Chrome y chromedriver instalados
- Cuenta de OpenAI con API key

### Setup

1. Crear entorno virtual:
```bash
python3 -m venv venv
source venv/bin/activate  # En Linux/Mac
# o
venv\Scripts\activate  # En Windows
```

2. Instalar dependencias:
```bash
pip install -r requirements.txt
```

3. Configurar variables de entorno:
El archivo `.env` ya estÃ¡ configurado con tu API key de OpenAI.

## Uso

### Ejecutar Etapa 1: Extract URLs

```bash
# Usar fecha de hoy
python stages/01_extract_urls.py

# Especificar fecha
python stages/01_extract_urls.py --date 2025-11-09
```

### Salida

- **CSV**: `data/raw/urls_YYYY-MM-DD.csv` con columnas:
  - `url`: URL del artÃ­culo
  - `title`: Titular
  - `source`: URL de la fuente
  - `extracted_at`: Timestamp de extracciÃ³n

- **Logs**: `logs/YYYY-MM-DD/01_extract_urls.log`

### Ejemplo de ejecuciÃ³n exitosa

```
2025-11-09 18:51:08 - INFO - Stage 01: Extract URLs - Starting for 2025-11-09
2025-11-09 18:51:08 - INFO - Loaded 2 enabled sources from config/sources.yml
2025-11-09 18:51:08 - INFO - Processing source: BBC News (https://www.bbc.com/news)
2025-11-09 18:51:08 - INFO - Extracted 44 raw links from BBC News
2025-11-09 18:51:08 - INFO - Filtered to 24 news articles from BBC News
2025-11-09 18:51:08 - INFO - Saved 24 URLs to data/raw/urls_2025-11-09.csv
2025-11-09 18:51:08 - INFO - Stage 01: Extract URLs - Completed in 15.80s
```

## ConfiguraciÃ³n

### Fuentes de Noticias

Editar `config/sources.yml` para aÃ±adir/modificar fuentes:

```yaml
sources:
  - id: "bbc"
    name: "BBC News"
    url: "https://www.bbc.com/news"
    selectors:
      - "a[data-testid='internal-link']"
      - "h2 a"
      - "h3 a"
    enabled: true
```

### CategorÃ­as

Editar `config/categories.yml` para modificar las categorÃ­as disponibles.

### ConfiguraciÃ³n LLM

Editar `config/llm.yaml` para ajustar modelos y parÃ¡metros por etapa.

## Tests

Ejecutar tests unitarios:

```bash
pytest tests/test_extract_urls.py -v
```

Para cambios que afecten a la webapp, ejecuta los tests end-to-end con Playwright contra `https://lewisembe.duckdns.org` y revisa los logs de consola del navegador en el reporte HTML:

```bash
cd webapp/frontend
npm install
npx playwright test --trace on --reporter=html
npx playwright show-report  # abre el reporte; revisa Trace -> Console
```

## Herramientas de Desarrollo

### Reset Stage Tool

Script para limpiar/resetear archivos generados por cualquier stage:

```bash
# Resetear Stage 01 para hoy (con confirmaciÃ³n)
python reset_stage.py --stage 01

# Ver quÃ© se borrarÃ­a sin borrar nada
python reset_stage.py --stage 01 --date 2025-11-09 --dry-run

# Resetear todos los stages para una fecha
python reset_stage.py --stage all --date 2025-11-09

# Solo borrar logs, mantener datos
python reset_stage.py --stage 01 --logs-only
```

Ver documentaciÃ³n completa en [RESET_TOOL.md](RESET_TOOL.md)

### Token Usage Tracker

Sistema automÃ¡tico de tracking de consumo de tokens de OpenAI:

```bash
# Ver resumen de uso de tokens
python view_token_usage.py

# Ver uso para una fecha especÃ­fica
python view_token_usage.py --date 2025-11-09

# Ver uso detallado por stage
python view_token_usage.py --stage 01 --detailed

# Filtrar por fecha y stage
python view_token_usage.py --date 2025-11-09 --stage 01
```

El tracking se registra automÃ¡ticamente en `logs/token_usage.csv` con:
- Timestamp de cada llamada
- Fecha de ejecuciÃ³n
- Stage que hizo la llamada
- Modelo utilizado (gpt-4o-mini, gpt-4o, etc.)
- OperaciÃ³n realizada
- Tokens de entrada y salida
- Costo en USD calculado automÃ¡ticamente

## Estructura del Proyecto

```
newsletter_utils/
â”œâ”€â”€ config/              # Archivos de configuraciÃ³n YAML
â”œâ”€â”€ stages/              # Scripts de cada etapa del pipeline
â”œâ”€â”€ common/              # Utilidades compartidas
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Datos crudos (CSVs)
â”‚   â””â”€â”€ processed/      # Datos procesados
â”œâ”€â”€ logs/               # Logs por fecha
â”œâ”€â”€ tests/              # Tests unitarios
â”œâ”€â”€ .env                # Variables de entorno
â”œâ”€â”€ requirements.txt    # Dependencias Python
â””â”€â”€ README.md          # Este archivo
```

## Notas TÃ©cnicas

### Selenium en ARM64/Raspberry Pi

El proyecto estÃ¡ configurado para usar chromium y chromedriver del sistema en arquitecturas ARM64.

### Formato CSV

Se usa TAB como separador (`\t`) en lugar de comas para evitar conflictos con el contenido de los titulares.

### Filtrado LLM

El filtrado con OpenAI identifica automÃ¡ticamente:
- âœ… ArtÃ­culos de noticias reales
- âŒ Enlaces de navegaciÃ³n (Inicio, Contacto, etc.)
- âŒ PÃ¡ginas de secciÃ³n/categorÃ­a
- âŒ Publicidad y contenido promocional
- âŒ Enlaces "Ver mÃ¡s", "Todas las noticias", etc.

## Problemas Conocidos

### El Confidencial no extrae enlaces

Los selectores CSS configurados para El Confidencial no estÃ¡n capturando enlaces. Esto se puede solucionar:

1. Inspeccionando la pÃ¡gina con DevTools del navegador
2. Identificando los selectores correctos
3. Actualizando `config/sources.yml`

### TÃ­tulos con saltos de lÃ­nea

Algunos tÃ­tulos contienen saltos de lÃ­nea. El mÃ³dulo `csv` de Python maneja esto correctamente al leer el archivo.

## PrÃ³ximos Pasos

1. Ajustar selectores CSS para El Confidencial
2. AÃ±adir mÃ¡s fuentes de noticias espaÃ±olas
3. Implementar Etapa 2: Upsert URLs y clasificaciÃ³n
4. Desarrollar base de datos SQLite
5. Implementar orquestador completo

## Autor

Pipeline desarrollado para automatizar la generaciÃ³n de newsletters personalizadas.
